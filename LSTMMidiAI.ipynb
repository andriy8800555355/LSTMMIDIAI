{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMVGc0E/TeLtqPFsJSzWRPj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andriy8800555355/LSTMMIDIAI/blob/main/LSTMMidiAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Завантажити необхідні лібки\n",
        "!pip install numpy tensorflow music21"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dzRKHqbsu8ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Навчити модель на ваших мідішках\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from music21 import converter, instrument, note, chord\n",
        "import glob\n",
        "import pickle\n",
        "import os\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def is_drive_mounted():\n",
        "    return os.path.exists('/content/drive')\n",
        "\n",
        "if not is_drive_mounted():\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "def get_notes():\n",
        "    notes = []\n",
        "    midi_folder = '/content/drive/MyDrive/LSTMMidi/MIDIs'\n",
        "    for file in glob.glob(f\"{midi_folder}/*.mid\"):\n",
        "        midi = converter.parse(file)\n",
        "        print(f\"Обробка {file}\")\n",
        "        notes_to_parse = midi.flat.notesAndRests\n",
        "        for element in notes_to_parse:\n",
        "            if isinstance(element, note.Note):\n",
        "                notes.append(str(element.pitch))\n",
        "            elif isinstance(element, chord.Chord):\n",
        "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "    return notes\n",
        "\n",
        "def prepare_sequences(notes, n_vocab):\n",
        "    sequence_length = 100\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "    n_patterns = len(network_input)\n",
        "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    network_input = network_input / float(n_vocab)\n",
        "    network_output = keras.utils.to_categorical(network_output)\n",
        "    return (network_input, network_output)\n",
        "\n",
        "def create_network(network_input, n_vocab):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.LSTM(\n",
        "        256,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(keras.layers.Dropout(0.3))\n",
        "    model.add(keras.layers.LSTM(512, return_sequences=True))\n",
        "    model.add(keras.layers.Dropout(0.3))\n",
        "    model.add(keras.layers.LSTM(256))\n",
        "    model.add(keras.layers.Dense(256))\n",
        "    model.add(keras.layers.Dropout(0.3))\n",
        "    model.add(keras.layers.Dense(n_vocab))\n",
        "    model.add(keras.layers.Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "    return model\n",
        "\n",
        "def train(epochs=50, batch_size=64):\n",
        "    notes = get_notes()\n",
        "    n_vocab = len(set(notes))\n",
        "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
        "    model = create_network(network_input, n_vocab)\n",
        "\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n",
        "\n",
        "    history = model.fit(network_input, network_output,\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        validation_split=0.2,\n",
        "                        callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "    output_folder = '/content/drive/MyDrive/LSTMMidi/MIDI_output'\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    model.save(f'{output_folder}/model.h5')\n",
        "    with open(f'{output_folder}/notes', 'wb') as filepath:\n",
        "        pickle.dump(notes, filepath)\n",
        "\n",
        "    return history\n",
        "\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Втрати на тренуванні')\n",
        "    plt.plot(history.history['val_loss'], label='Втрати на валідації')\n",
        "    plt.title('Втрати моделі')\n",
        "    plt.xlabel('Епоха')\n",
        "    plt.ylabel('Втрати')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    history = train()\n",
        "    plot_history(history)\n",
        "    print(\"Навчання завершено. Модель і ноти збережено на Google Drive.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Q054h6Vcu9BU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Налаштування генерації MIDI\n",
        "# @markdown Введіть бажані параметри для генерації MIDI-файлу.\n",
        "тривалість_в_хвилинах = 3  # @param {type: \"slider\", min: 1, max: 10}\n",
        "фантазія = 2  # @param {type: \"slider\", min: 0.1, max: 2.0, step: 0.1}\n",
        "# @markdown ---\n",
        "# @markdown *Тривалість в хвилинах* обмежує тривалість генерованого MIDI-файлу.\n",
        "# @markdown *Фантазія (креативність)* контролює непередбачуваність нот (низьке значення - більше передбачуваності, високе - більше креативності).\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "from music21 import instrument, note, stream, chord\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import random\n",
        "from google.colab import drive, files\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def is_drive_mounted():\n",
        "    return os.path.exists('/content/drive')\n",
        "\n",
        "if not is_drive_mounted():\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "def generate(duration_minutes=тривалість_в_хвилинах, temperature=фантазія):\n",
        "    with open('/content/drive/MyDrive/LSTMMidi/MIDI_output/notes', 'rb') as filepath:\n",
        "        notes = pickle.load(filepath)\n",
        "\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "    n_vocab = len(set(notes))\n",
        "\n",
        "    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\n",
        "    model = keras.models.load_model('/content/drive/MyDrive/LSTMMidi/MIDI_output/model.h5')\n",
        "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab, duration_minutes, temperature)\n",
        "    midi_stream = create_midi(prediction_output)\n",
        "\n",
        "    output_path = '/content/drive/MyDrive/LSTMMidi/MIDI_output/generated_output.mid'\n",
        "    save_midi_file(midi_stream, output_path)\n",
        "\n",
        "    print(f\"Згенеровано та збережено MIDI файл за адресою: {output_path}\")\n",
        "\n",
        "    visualize_generated_notes(prediction_output)\n",
        "\n",
        "def prepare_sequences(notes, pitchnames, n_vocab):\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "    sequence_length = 100\n",
        "    network_input = []\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "    network_input = np.reshape(network_input, (len(network_input), sequence_length, 1))\n",
        "    normalized_input = network_input / float(n_vocab)\n",
        "    return (network_input, normalized_input)\n",
        "\n",
        "def generate_notes(model, network_input, pitchnames, n_vocab, duration_minutes, temperature):\n",
        "    start = np.random.randint(0, len(network_input)-1)\n",
        "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "    pattern = network_input[start]\n",
        "    prediction_output = []\n",
        "    notes_per_minute = 120\n",
        "    max_notes = int(duration_minutes * notes_per_minute)\n",
        "\n",
        "    for note_index in range(max_notes):\n",
        "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
        "        prediction_input = prediction_input / float(n_vocab)\n",
        "        prediction = model.predict(prediction_input, verbose=0)\n",
        "\n",
        "        prediction = np.log(prediction + 1e-7) / temperature\n",
        "        prediction = np.exp(prediction) / np.sum(np.exp(prediction))\n",
        "\n",
        "        if random.random() < 0.8:\n",
        "            index = np.argmax(prediction)\n",
        "        else:\n",
        "            index = np.random.choice(len(prediction[0]), p=prediction[0])\n",
        "\n",
        "        result = int_to_note[index]\n",
        "        prediction_output.append(result)\n",
        "        pattern = np.append(pattern, index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "\n",
        "    return prediction_output\n",
        "\n",
        "def create_midi(prediction_output):\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    for pattern in prediction_output:\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                new_note = note.Note(int(current_note))\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    return midi_stream\n",
        "\n",
        "def save_midi_file(midi_stream, file_path):\n",
        "    \"\"\"Зберігає згенерований MIDI файл на диск.\"\"\"\n",
        "    midi_stream.write('midi', fp=file_path)\n",
        "\n",
        "def visualize_generated_notes(prediction_output):\n",
        "    pitches = []\n",
        "\n",
        "    for pattern in prediction_output:\n",
        "        if isinstance(pattern, note.Note):\n",
        "            pitches.append(pattern.pitch.midi)\n",
        "        elif isinstance(pattern, chord.Chord):\n",
        "            pitches.append(pattern.root().midi)\n",
        "        elif '.' in pattern or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            chord_pitches = [int(n) for n in notes_in_chord]\n",
        "            pitches.append(np.mean(chord_pitches))\n",
        "        else:\n",
        "            try:\n",
        "                note_obj = note.Note(pattern)\n",
        "                pitches.append(note_obj.pitch.midi)\n",
        "            except:\n",
        "                print(f\"Не вдалося інтерпретувати шаблон: {pattern}\")\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.plot(range(len(pitches)), pitches)\n",
        "    plt.title('Згенеровані ноти')\n",
        "    plt.xlabel('Послідовність нот')\n",
        "    plt.ylabel('MIDI Висота')\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    generate()"
      ],
      "metadata": {
        "id": "5ad7D3IUvt9j",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}